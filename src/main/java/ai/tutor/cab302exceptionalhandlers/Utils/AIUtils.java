package ai.tutor.cab302exceptionalhandlers.Utils;

import ai.tutor.cab302exceptionalhandlers.model.Chat;
import ai.tutor.cab302exceptionalhandlers.model.Message;

import io.github.ollama4j.OllamaAPI;
import io.github.ollama4j.exceptions.OllamaBaseException;
import io.github.ollama4j.models.chat.*;
import io.github.ollama4j.utils.Options;
import io.github.ollama4j.utils.OptionsBuilder;

import java.io.IOException;
import java.io.InputStream;
import java.nio.charset.StandardCharsets;
import java.util.List;
import java.util.HashMap;

import com.google.gson.Gson;

/**
 * Singleton utility class for interacting with the Ollama AI API.
 * <p>
 * This class handles the construction of prompts, communication with the Ollama API,
 * and parsing of AI responses.
 *
 * <p>Usage Example:
 * <pre>
 * MessageResponseFormat response = AIUtils.getInstance().generateResponse(
 *     chatHistory,
 *     chatConfig,
 *     isQuizMode
 * );</pre>
 *
 * @author Justin.
 */
public class AIUtils {
    private static AIUtils instance;

    private final OllamaAPI ollamaAPI;
    private final String modelName = "qwen3:4b";
    private final OllamaChatRequestBuilder ollamaBuilder = OllamaChatRequestBuilder.getInstance(modelName);
    private final HashMap<String, String> prompts = new HashMap<>();
    private final Gson gson = new Gson();
    private boolean verbose = false;

    /* Model Settings (change if you're using a different model) */
    private final float temperature = 0.9f;
    private final int numPredict = -2;
    private final int numCtx = 40960;

    /**
     * The response format for the AI's responses.
     */
    public class ModelResponseFormat {
        @SuppressWarnings("unused")
        public final String response;

        @SuppressWarnings("unused")
        public final boolean isError;

        /** An array of quizzes, if generated by the AI. */
        public final QuizFormat[] quizzes;

        /**
         * Constructor of {@code ModelResponseFormat}.
         * @param isError True if an error occurred, false otherwise.
         * @param response The AI's response text.
         * @param quizzes An array of {@link QuizFormat} objects, or null if no quizzes were generated.
         */
        public ModelResponseFormat(boolean isError, String response, QuizFormat[] quizzes) {
            this.response = response;
            this.isError = isError;
            this.quizzes = quizzes;
        }

        public String getQuizTitle() {
            if (quizzes != null && quizzes.length > 0) {
                return quizzes[0].getQuizTitle();
            }
            return null;
        }

        public List<Question> getQuizQuestions() {
            if (quizzes != null && quizzes.length > 0) {
                return List.of(quizzes[0].questions);
            }
            return null;
        }
    }

    /**
     * Structure of a quiz generated by the AI.
     * <p>
     * This class contains the title of this quiz and an array of {@link Question} objects.
     *
     */
    public class QuizFormat {
        @SuppressWarnings("unused")
        private final String quizTitle;

        @SuppressWarnings("unused")
        private final Question[] questions;

        /**
         * Constructor of {@code QuizFormat}.
         * @param quizTitle The title of this quiz.
         * @param questions An array of questions for this quiz.
         */
        public QuizFormat(String quizTitle, Question[] questions) {
            this.quizTitle = quizTitle;
            this.questions = questions;
        }

        public String getQuizTitle() {
            return quizTitle;
        }

        public Question[] getQuestions() {
            return questions;
        }
    }

    /**
     * A singular question in a quiz generated by the AI.
     */
    public class Question {
        @SuppressWarnings("unused")
        private final int questionNumber;

        @SuppressWarnings("unused")
        private final String questionContent;

        @SuppressWarnings("unused")
        private final Option[] options;

        /**
         * Constructor of {@code Question}.
         * @param questionNumber The question number (e.g., 1, 2, 3).
         * @param questionText The text content of this question.
         * @param options An array of answer options for this question.
         */
        public Question(int questionNumber, String questionText, Option[] options) {
            this.questionNumber = questionNumber;
            this.questionContent = questionText;
            this.options = options;
        }

        public int getQuestionNumber() {
            return questionNumber;
        }

        public String getQuestionContent() {
            return questionContent;
        }

        public Option[] getOptions() {
            return options;
        }
    }

    /**
     * Format of a single option in a quiz question generated by the AI.
     */
    public class Option {
        @SuppressWarnings("unused")
        private final String optionLetter;

        @SuppressWarnings("unused")
        private final String optionText;

        @SuppressWarnings("unused")
        private final boolean isAnswer;

        /**
         * Constructor of {@code Option}.
         * @param optionLetter The letter identifying this option (e.g., "A", "B").
         * @param optionText The text content of this option.
         * @param isAnswer True if this option is the correct answer, false otherwise.
         */
        public Option(String optionLetter, String optionText, boolean isAnswer) {
            this.optionLetter = optionLetter;
            this.optionText = optionText;
            this.isAnswer = isAnswer;
        }

        public String getOptionLetter() {
            return optionLetter;
        }

        public String getOptionText() {
            return optionText;
        }

        public boolean isAnswer() {
            return isAnswer;
        }
    }

    private AIUtils() throws IOException {
        this.ollamaAPI = new OllamaAPI("http://127.0.0.1:11434/");
        this.ollamaAPI.setVerbose(false);
        loadPrompts();
    }

    /**
     * Gets the singleton instance of {@code AIUtils}.
     *
     * @return The singleton instance.
     * @throws RuntimeException if initialization fails.
     */
    public static AIUtils getInstance() {
        if (instance == null) {
            try {
                instance = new AIUtils();
            } catch (IOException e) {
                throw new RuntimeException("Failed to initialize AIUtils: " + e.getMessage(), e);
            }
        }
        return instance;
    }

    /**
     * Validates the structure and content of an AI-generated quiz response.
     * <p>
     * This method thoroughly checks the response format to ensure it contains valid quizzes,
     * questions, and options. First, responses cannot be null or empty.
     * If the response is valid, it checks each quiz for a title and questions.
     * <p>
     * A quiz must have at least one question and a list of questions.
     * Furthermore, each question must satisfy all the variables in the {@link Question} class.
     * Each question must have a valid question number, content, and at least one option.
     * Ideally, the AI should generate at least one correct answer option for each question. If
     * not, the quiz response is considered invalid.
     * <p>
     * @param response The {@link ModelResponseFormat} to validate.
     * @return True if the quiz response is valid, false otherwise.
     */
    public static boolean validateQuizResponse(ModelResponseFormat response) {
        if (response == null || response.isError || response.quizzes == null || response.quizzes.length == 0) {
            return false;
        }

        for (QuizFormat quiz : response.quizzes) {
            if (quiz == null ||
                quiz.getQuizTitle() == null || quiz.getQuizTitle().isEmpty() ||
                quiz.getQuestions() == null || quiz.getQuestions().length == 0) {
                return false;
            }

            for (Question question : quiz.getQuestions()) {
                if (question == null ||
                    question.questionNumber < 1 ||
                    question.getQuestionContent() == null || question.getQuestionContent().isEmpty() ||
                    question.options == null || question.options.length == 0) {
                    return false;
                }

                boolean hasCorrectOption = false;
                for (Option option : question.options) {
                    if (option == null ||
                        option.optionLetter == null || option.optionLetter.isEmpty() ||
                        option.optionText == null || option.optionText.isEmpty()) {
                        return false;
                    }

                    hasCorrectOption |= option.isAnswer;
                    if (hasCorrectOption) {
                        break;
                    }
                }

                if (!hasCorrectOption) {
                    return false;
                }
            }
        }

        return true;
    }

    /**
     * Pings Ollama host to check if it is running.
     * <p>
     * Ollama is by default running locally at http://127.0.0.1:11434/.
     * <p>
     * On Windows, having the Ollama host set to "localhost" will not be
     * equivalent to 127.0.0.1
     * <p>
     * To setup ollama, `ollama serve` must be run in the terminal.
     *
     * @return True if Ollama is running, false otherwise.
     */
    public boolean isOllamaRunning() {
        try {
            return ollamaAPI.ping();
        } catch ( RuntimeException e) {
            System.err.println("Error pinging Ollama API: " + e.getMessage());
            return false;
        }
    }

    /**
     * Calls /api/tags on the Ollama host to check if {@link #modelName} is available.
     *
     * @return True if the model is available, false otherwise.
     */
    public boolean hasModel() {
        try {
            ollamaAPI.getModelDetails(modelName);
            return true;
        } catch (Exception e) {
            System.err.println("Error checking model: " + e.getMessage());
            return false;
        }
    }

    public String getModelName() {
        return modelName;
    }

    /**
     * Sets the verbosity of {@link OllamaAPI} output.
     * <p>
     * By default, this is false when {@link OllamaAPI} is initialized.
     *
     * @param verbose True to enable verbose output, false to disable.
     */
    public void setVerbose(boolean verbose) {
        this.verbose = verbose;
    }

    /**
     * Loads system_prompt.txt and quiz_system_prompt.txt from classpath to populate the prompts hashmap.
     * <p>
     * Both system prompts are stored locally in src/main/resources/ai/tutor/cab302exceptionalhandlers/prompts/
     * <p>
     * These system prompts are used as the system prompt for AI's responses in tutor and quiz modes.
     *
     * @return True if verbose output is enabled, false otherwise.
     * @throws IOException if there is an error reading the prompt files.
     */
    private void loadPrompts() throws IOException {
        String systemTutorPromptPath = "/ai/tutor/cab302exceptionalhandlers/prompts/system_prompt.txt";
        String systemQuizPromptPath = "/ai/tutor/cab302exceptionalhandlers/prompts/quiz_system_prompt.txt";

        String tutorPrompt = loadPromptFromFile(systemTutorPromptPath);
        String quizPrompt = loadPromptFromFile(systemQuizPromptPath);

        prompts.put("tutor", tutorPrompt);
        prompts.put("quiz", quizPrompt);
    }

    /**
     * Loads a prompt from a file in the classpath.
     *
     * @param promptPath The path to the resource file (e.g., "/path/to/prompt.txt").
     * @return The prompt content as a String.
     * @throws IOException if there is an error reading the file.
     */
    private String loadPromptFromFile(String promptPath) throws IOException {
        try (InputStream is = AIUtils.class.getResourceAsStream(promptPath)) {
            if (is == null) {
                throw new IOException("Prompt file not found in classpath: " + promptPath);
            }
            return new String(is.readAllBytes(), StandardCharsets.UTF_8);
        }
    }

    /**
     * Checks if the product OllamaChatRequest response is empty
     *
     * @param ollamaRequest The {@link OllamaChatRequest} to check.
     * @return True if the request is null or has no messages, false otherwise.
     */
    private boolean ollamaResultIsNull(OllamaChatRequest ollamaRequest) {
        return ollamaRequest == null || ollamaRequest.getMessages() == null
                || ollamaRequest.getMessages().isEmpty();
    }

    /**
     * Calls /api/chat on the Ollama host generating an AI response based on chat history and configuration.
     * <p>
     * The AI model is configured accordingly using {@link OptionsBuilder} with the
     * specified temperature, number of predictions, and context size.
     * These model parameters are highly dependant on which model is being used.
     * <p>
     * After the model is generates a response, it's thinking tokens are formatted out,
     * the response is further processed by either {@link #processQuizResponse(String)}
     * or {@link #processChatResponse(String)} methods assuming the response is in
     * JSON format, then the response is returned in a {@link ModelResponseFormat}.
     * <p>
     * If the model response fails, the default response is an error message.
     * <p>
     * It is expected but not enforced that there should be a system prompt
     * for the AI to follow. The system prompt is constructed based on the
     * provided chat configuration and whether the response is for a quiz or general chat.
     * <p>
     * System prompts are loaded via {@link #loadPrompts()} method.
     * <p>
     *
     * @param history The list of previous {@link Message} objects in the chat.
     * @param chatConfig The {@link Chat} configuration (e.g., personality, quiz settings).
     * @param isQuizMode True if a quiz response is requested, false for a general chat response.
     * @return A {@link ModelResponseFormat} containing the AI's response.
     */
    public ModelResponseFormat generateResponse(List<Message> history, Chat chatConfig, boolean isQuizMode) {
        try {
            String promptTemplate = isQuizMode ? prompts.get("quiz") : prompts.get("tutor");

            String systemPrompt = String.format(
                promptTemplate,
                chatConfig.getName(),
                chatConfig.getResponseAttitude(),
                chatConfig.getQuizDifficulty(),
                chatConfig.getQuizLength(),
                chatConfig.getEducationLevel(),
                chatConfig.getStudyArea()
            );

            Options options = new OptionsBuilder()
                .setTemperature(this.temperature)
                .setNumPredict(this.numPredict)
                .setNumCtx(this.numCtx)
                .build();

            ollamaBuilder.reset();
            ollamaBuilder.withMessage(OllamaChatMessageRole.SYSTEM, systemPrompt);
            ollamaBuilder.withOptions(options);

            for (Message msg : history) {
                OllamaChatMessageRole role = msg.getFromUser() ? OllamaChatMessageRole.USER : OllamaChatMessageRole.ASSISTANT;
                ollamaBuilder.withMessage(role, msg.getContent());

                if (verbose) {
                    System.out.println(String.format(
                        "%s: \n---\n%s\n---", role.toString(), msg.getContent()
                    ));
                }
            }

            OllamaChatRequest ollamaRequest = ollamaBuilder.build();
            OllamaChatResult ollamaResult = ollamaAPI.chat(ollamaRequest);

            if (ollamaResultIsNull(ollamaRequest)) {
                throw new OllamaBaseException("Received null response from Ollama API.");
            }

            String response = ollamaResult.getResponseModel().getMessage().getContent();
            if (verbose) {
                System.out.println(String.format(
                    "AI Response: \n---\n%s\n---", response
                ));
            }

            /* Format out the <thinking> tokens and everything between that */
            String[] responseParts = response.split("<think>");
            StringBuilder formattedResponse = new StringBuilder();
            for (String part : responseParts) {
                    if (part.contains("</think>")) {
                    String[] subParts = part.split("</think>");
                    formattedResponse.append(subParts[1]);
                } else {
                    formattedResponse.append(part);
                }
            }

            // do NOT remove `\n` or it will mess up the AI response
            response = formattedResponse.toString();

            if (isQuizMode) {
                return processQuizResponse(response);
            } else {
                return processChatResponse(response);
            }

        } catch (Exception e) {
            System.err.println("Error generating response: " + e.getMessage());
            return new ModelResponseFormat(
                true,
                "Error: Unable to generate response from AI.",
                null
            );
        }
    }

    /**
     * Removes JSON code blocks and converts the response into a {@link ModelResponseFormat} for quiz responses.
     * <p>
     * This method extracts the JSON content from the AI's response, it assumes
     * the response is in a format that includes JSON code blocks (e.g., ```json ... ```).
     * Using {@link gson}, the JSON content is parsed into a {@link ModelResponseFormat} object.
     * If the response does not contain valid JSON or if an error occurs during parsing,
     * this method returns an error message in {@link ModelResponseFormat}.
     *
     * @param response The AI's response string.
     * @return A {@link ModelResponseFormat} containing the quiz data or an error message.
     */
    private ModelResponseFormat processQuizResponse(String response) {
        try {
            String jsonContent = response;
            if (response.contains("```json")) {
                jsonContent = response.substring(response.indexOf("```json") + 7);
                jsonContent = jsonContent.substring(0, jsonContent.indexOf("```"));
                jsonContent = jsonContent.trim();
            } else if (response.contains("```")) {
                jsonContent = response.substring(response.indexOf("```") + 3);
                jsonContent = jsonContent.substring(0, jsonContent.indexOf("```"));
                jsonContent = jsonContent.trim();
            }

            QuizFormat quizData = gson.fromJson(jsonContent, QuizFormat.class);

            return new ModelResponseFormat(
                false,
                response,
                new QuizFormat[] { quizData }
            );
        } catch (Exception e) {
            System.err.println("Error parsing quiz response: " + e.getMessage());
            return new ModelResponseFormat(
                true,
                "Error: Unable to parse quiz response from AI. " + e.getMessage(),
                null
            );
        }
    }

    /**
     * Removes JSON code blocks and converts the response into a {@link ModelResponseFormat} for chat responses.
     * <p>
     * This method extracts the JSON content from the AI's response, it assumes
     * the response is in a format that includes JSON code blocks (e.g., ```json ... ```).
     * Using {@link gson}, the JSON content is parsed into a {@link ModelResponseFormat} object.
     * If the response does not contain valid JSON or if an error occurs during parsing,
     * this method returns an error message in {@link ModelResponseFormat}.
     *
     * @param response The AI's response string.
     * @return A {@link ModelResponseFormat} containing the quiz data or an error message.
     */
    private ModelResponseFormat processChatResponse(String response) {
        try {
            ModelResponseFormat responseFormat = gson.fromJson(response, ModelResponseFormat.class);
            if (responseFormat == null) {
                System.err.println("Error: Unable to parse response from AI.");
                return new ModelResponseFormat(
                    false,
                    "Error: Unable to parse response from AI.",
                    null
                );
            }
            return responseFormat;
        } catch (Exception e) {
            return new ModelResponseFormat(
                false,
                response,
                null
            );
        }
    }
}
